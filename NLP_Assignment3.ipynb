{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP24nt4nafg2Zypq1pHJkZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KxxHyoRim/2022-2-NLP/blob/main/NLP_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. The IOB format categorizes tagged tokens as I, O and B. Why are three tags necessary? What problem would be caused if we used I and O tags exclusively?\n",
        "\n",
        "```\n",
        "As B marks the begining of the token,\n",
        "we could recognize different tokens even if they appear next to each other. \n",
        "```\n"
      ],
      "metadata": {
        "id": "XdeqEH8H_19s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Write a tag pattern to match noun phrases containing plural head nouns, e.g. \"many/JJ researchers/NNS\", \"two/CD weeks/NNS\", \"both/DT new/JJ positions/NNS\". Try to do this by generalizing the tag pattern that handled singular noun phrases."
      ],
      "metadata": {
        "id": "BImhU2aeAbbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "testData = [(\"many\", \"JJ\"), (\"researchers\", \"NNS\"), (\"two\", \"CD\"), (\"weeks\", \"NNS\"), (\"both\",\"DT\"), (\"new\", \"JJ\"), (\"positions\", \"NNS\")]\n",
        "grammar = \"NP:{<DT>?<CD>?<JJ>*<NNS>}\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "result = cp.parse(testData)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGi9-aFXCswh",
        "outputId": "af3619db-7488-4ec5-b26c-a302fa739b90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP many/JJ researchers/NNS)\n",
            "  (NP two/CD weeks/NNS)\n",
            "  (NP both/DT new/JJ positions/NNS))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3. Explain the meaning of the performance metrics such as Accuracy, Precision, Recall, F-measure which are generated by \"accuracy\" function\n"
      ],
      "metadata": {
        "id": "vajHGuhbABQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Accuracy = 올바르게 예측된 데이터 수 / 전체 데이터 수\n",
        "Precision = True로 예측된 데이터 중 실제로 True일 확률\n",
        "Recall = 실제로 True 인 데이터를 True라고 예측한 확률\n",
        "F-measue = Precision, Recall의 조화평균이다.\n",
        "```\n",
        "\n",
        "```\n",
        "Accuracy = TP + TN / TP + TN + FP + FN\n",
        "Precision = TP / TP + FP\n",
        "Recall = TP / TP + FN\n",
        "F1 Schore = 2 * (Precision*Recall)/(Precision + Recall)\n",
        "\n"
      ],
      "metadata": {
        "id": "OYo7sCQ_ExSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4. Investigate what are the \"UnigramChunker\" and \"BigramChunker\". Why \"BigramChunker\" generates higher evaluation scores?\n"
      ],
      "metadata": {
        "id": "ehuVYPGcAm4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "UnigramChunker maps POS tags to IOB tags.\n",
        "The chunks are the unigrams, instead of the words.\n",
        "Unlike the UnigramChunker, BigramChunker returns the result with bigrams.\n",
        "\n",
        "BigramChunker is effective, as it could be sensitive to consider the chunk tag on the previous word.\n",
        "``` \n"
      ],
      "metadata": {
        "id": "-Ol8TgpkHAgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Consider the sentence Kim arrived or Dana left and everyone cheered. Write down the parenthesized forms to show the relative scope of and and or. Generate tree structures corresponding to both of these interpretations."
      ],
      "metadata": {
        "id": "QJe44t2-AkIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import CFG\n",
        "\n",
        "sent = \"Kim arrived or Dana left and everyone cheered\"\n",
        "sent = [word for word in sent.split()]\n",
        "print(sent)\n",
        "groucho_grammar = CFG.fromstring(\"\"\"\n",
        "  S -> CP | VP \n",
        "  CP -> VP C VP | CP C VP | VP C CP\n",
        "  VP -> NP V \n",
        "  NP -> 'Kim' | 'Dana' | 'everyone'\n",
        "  V -> 'arrived' | 'left' |'cheered'\n",
        "  C -> 'or' | 'and'\n",
        "  \"\"\")\n",
        "print(groucho_grammar.productions() )\n",
        "parser = nltk.ChartParser(groucho_grammar)\n",
        "trees = parser.parse(sent)\n",
        "for tree in trees:\n",
        "    print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPyJhSf7LTTy",
        "outputId": "1cdf0a66-6a0b-4e7e-84c7-1063e70a8b42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Kim', 'arrived', 'or', 'Dana', 'left', 'and', 'everyone', 'cheered']\n",
            "[S -> CP, S -> VP, CP -> VP C VP, CP -> CP C VP, CP -> VP C CP, VP -> NP V, NP -> 'Kim', NP -> 'Dana', NP -> 'everyone', V -> 'arrived', V -> 'left', V -> 'cheered', C -> 'or', C -> 'and']\n",
            "(S\n",
            "  (CP\n",
            "    (CP (VP (NP Kim) (V arrived)) (C or) (VP (NP Dana) (V left)))\n",
            "    (C and)\n",
            "    (VP (NP everyone) (V cheered))))\n",
            "(S\n",
            "  (CP\n",
            "    (VP (NP Kim) (V arrived))\n",
            "    (C or)\n",
            "    (CP\n",
            "      (VP (NP Dana) (V left))\n",
            "      (C and)\n",
            "      (VP (NP everyone) (V cheered)))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. In this exercise you will manually construct some parse trees.\n",
        "\n",
        "Write code to produce two trees, one for each reading of the phrase old men and women"
      ],
      "metadata": {
        "id": "Ky3gu0BNArkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = nltk.CFG.fromstring(\"\"\"\n",
        "    PHRASE -> AdjP | NP CON NP\n",
        "    NP -> Adj N | N\n",
        "    AdjP -> Adj Obj\n",
        "    Obj -> N CON N\n",
        "    Adj -> 'old'\n",
        "    N -> 'men' | 'women'\n",
        "    CON -> 'and'\n",
        "\"\"\")\n",
        "\n",
        "sent1 = ['old', 'men', 'and', 'women']\n",
        "\n",
        "rd_parser = nltk.RecursiveDescentParser(grammar)\n",
        "\n",
        "for tree in rd_parser.parse(sent1):\n",
        "    print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCiFEnwfLyTU",
        "outputId": "4f051ebd-b6a8-490a-f408-b0b499659681"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(PHRASE (AdjP (Adj old) (Obj (N men) (CON and) (N women))))\n",
            "(PHRASE (NP (Adj old) (N men)) (CON and) (NP (N women)))\n"
          ]
        }
      ]
    }
  ]
}